---
title: "412_Housing"
author: "David Sun, Harrison DiStefano, Yuxiu Zheng"
date: "11/26/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(ggplot2)
#library(plyr)
library(dplyr)
library(glmnet)
library(car)
library(gt)

```

#Examine Basic Data Frame
```{r}
df<- read.csv('USA_Housing.csv')
names(df) <- c("AvgIncome", "AvgHouseAge", "AvgNumRooms", "AvgNumBedrooms", "AreaPopulation", "Price", "Address")

dim(df)         # 5000 X 7
df$state <- sub(".*\\b([A-Z]{2}) \\d{5}.*", "\\1", df[,7])  # get the state from address
head(df,5)
df1<-df[,c(1:6,8)] # remove address column
head(df1,5)

df1 %>%
dplyr::count(df1$state, sort = TRUE)
```
In our original data, we have 5000 records with 7 variables. We extracted state from Address variable 

```{r}
s_df1<-summary(df1)
s_df1
```


#Data Cleaning
## Na's
```{r}
sum(is.na(df1))  # count how many NA's
```
no NA's

##Outlier

###Price
```{r}
boxplot(df1$Price)
iqr_price<-IQR(df1$Price)
df2 = subset(df1, Price>=quantile(df1$Price, 0.25)-1.5*iqr_price & Price<=quantile(df1$Price, 0.75)+1.5*iqr_price )
summary(df2)
boxplot(df2$Price)
```

Since Price is our response variable, we start with it first by using 1.5 * IQR method to remove outliers

We removed 35 outliers.

### Average Income 
```{r}
boxplot(df2$AvgIncome)
iqr_ainc<-IQR(df2$AvgIncome)
df3 = subset(df2, AvgIncome>=quantile(df2$AvgIncome, 0.25)-1.5*iqr_ainc & AvgIncome<=quantile(df2$AvgIncome, 0.75)+1.5*iqr_ainc )
summary(df3)
boxplot(df3$AvgIncome)
```
We removed 29 more outliers on Average Income.

For the rest of the variables, even they have outliers bases on IQR method, but they do not affect our models much. 



# EDA 
```{r}
df_corr<-cor(df1)
df_corr
corrplot(df_corr, method = "circle")
```

We see AvgNumRooms and AvgNumBedrooms are highly corrected, and by intuition, more rooms would have more bedrooms. Hypothetically, we will remove AvgNumRooms in our models, later will be shown in our analysis. We also see AvgIncome is closely correlated with Price.  


###Price

```{r}
qplot(df1$Price,xlab = 'Price',main = 'Price Hist',col ='red',bins = 30) # price
```

Price 1m -1.5m

###Avg Area Income
```{r}
qplot(df3$AvgIncome,xlab = 'Avg Area Income',bins = 20,col ='red')
```
60k-80k

###Average House Age
```{r}
qplot(df3$AvgHouseAge,xlab = 'Avg House Age',main ='Avg House Age Hist',bins = 9,col ='red')
```
5-7 years old

###Average Number of Rooms

```{r}
qplot(df1$AvgNumRooms,xlab = 'Avg Num Rooms', main ='Avg Num Rooms Hist',bins = 10,col ='red')
```

###Average Number of Bedrooms
```{r}
qplot(df1$AvgNumBedrooms,xlab = 'Avg Num Bedrooms',main = 'Avg Num Bedrooms Hist',bins = 7,col ='red')
```
2-5

Area Population
```{r}
qplot(df1$AreaPopulation,xlab = 'Area Population',bins = 20,col ='red')
```
30k-45k


##Linear Regression (Harrison)

```{r collinearity}
# eigenvalue method
numeric_feature <- df3[, c(1:5)]

X <- as.matrix(numeric_feature)
XtX <- t(X) %*% X

eigen(XtX)
```



```{r lm}
# Linear Model
lm_housing <- lm(Price ~ AvgIncome + AvgHouseAge + AvgNumRooms + AvgNumBedrooms + AreaPopulation, data=df3)
plot(lm_housing)
summary(lm_housing)

# VIF
vif(lm_housing)
```

Since all features except average number of bedrooms are significant and it is correlated with the average number of rooms, let's remove that feature from the model.

```{r lm2}
lm_housing2 <- lm(Price ~ AvgIncome + AvgHouseAge + AvgNumRooms + AreaPopulation, data=df)
plot(lm_housing2)
summary(lm_housing2)

# VIF
vif(lm_housing2)
```

##Ridge (Yuxiu)
```{r}
numeric_features <- as.matrix(df3[, c(1:5)])

lambdas_to_try <- seq(0, 1, by = 0.001)
ridge_housing_cv <- cv.glmnet(numeric_features, df3$Price, lambda = lambdas_to_try, standardize = TRUE, nfolds = 10)
ridge_housing_cv$lambda.min
ridge_housing <- glmnet(numeric_features, df3$Price, alpha = 0, lambda = ridge_housing_cv$lambda.min, standardize = TRUE)

adj_R2 <- function(data, resids, n, p){
  TSS = sum((data - mean(data))^2)
  RSS = sum(resids^2)
  adj_R2 = 1 - (RSS/(n - p))/(TSS/(n - 1))
  return(cat("The adjusted R^2 is:", adj_R2, "\n"))
}

adj_R2(df3$Price, df3$Price - predict(ridge_housing, newx = numeric_features), nrow(df3), ncol(df3)-1)
```

The adjusted R^2 is about $0.913$, which is close to 1.




